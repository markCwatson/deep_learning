{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Digit Recognizer\n\nThis is for Kaggle's [Digit Recognizer competition](https://www.kaggle.com/competitions/digit-recognizer)\n\nThis approach is based off of Andrew Ng's Neural Networks and Deep Learning course in the [Deep Learning specialization on Coursera](https://www.coursera.org/specializations/deep-learning); however, it has been adapted for this particular problem.\n\nThis approach includes a implementation of a deep neural network utilizing numpy.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport copy","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.517671Z","iopub.execute_input":"2023-12-17T22:54:35.518009Z","iopub.status.idle":"2023-12-17T22:54:35.523408Z","shell.execute_reply.started":"2023-12-17T22:54:35.517978Z","shell.execute_reply":"2023-12-17T22:54:35.522647Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def data_prep(raw, num_classes=10):\n    \"\"\"\n    Argument:\n    raw -- The raw data rad from a csv file\n    num_classes -- The number of labels\n\n    Returns:\n    x -- Normalized\n    y_one_hot -- One-hot encoding of labels\n    \"\"\"\n    data = np.array(raw)\n    m, n = data.shape\n    print(\"data.shape = (m = {0}, n = {1})\".format(m, n))\n    \n    # Extract labels and feature set\n    y = data[:, 0]\n    X = data[:, 1:] / 255\n    \n    # Transpose X to match the expected shape (number_of_features, number_of_examples)\n    X = X.T\n    \n    # Convert labels to one-hot encoding\n    y_one_hot = np.zeros((m, num_classes))\n    y_one_hot[np.arange(m), y] = 1\n\n    # Transpose y_one_hot to match the expected shape (number_of_classes, number_of_examples)\n    y_one_hot = y_one_hot.T\n    \n    print(\"X.shape = {0}\".format(X.shape))\n    print(\"y_one_hot.shape = {0}\".format(y_one_hot.shape))\n    \n    return X, y_one_hot","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.524829Z","iopub.execute_input":"2023-12-17T22:54:35.525079Z","iopub.status.idle":"2023-12-17T22:54:35.538741Z","shell.execute_reply.started":"2023-12-17T22:54:35.525056Z","shell.execute_reply":"2023-12-17T22:54:35.537098Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"def relu(Z):\n    \"\"\"\n    Implements the ReLU function.\n\n    Arguments:\n    Z -- Output of the linear layer, of any shape\n\n    Returns:\n    A -- Post-activation parameter, of the same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    A = np.maximum(0, Z)\n    cache = Z  \n    assert (A.shape == Z.shape)\n    \n    return A, cache","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.540717Z","iopub.execute_input":"2023-12-17T22:54:35.541074Z","iopub.status.idle":"2023-12-17T22:54:35.551975Z","shell.execute_reply.started":"2023-12-17T22:54:35.541045Z","shell.execute_reply":"2023-12-17T22:54:35.550466Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"def softmax(Z):\n    \"\"\"\n    For multi-class classification.\n\n    Arguments:\n    Z -- numpy array of any shape\n\n    Returns:\n    A -- Softmax output, same shape as Z\n    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    # subtract the maximum of Z from each Z before applying exp to stabilize the computation.\n    Z_shifted = Z - np.max(Z, axis=0, keepdims=True)\n    A = np.exp(Z_shifted) / np.sum(np.exp(Z_shifted), axis=0, keepdims=True)\n    assert (A.shape == Z_shifted.shape)\n    cache = A\n    \n    return A, cache","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.554158Z","iopub.execute_input":"2023-12-17T22:54:35.554616Z","iopub.status.idle":"2023-12-17T22:54:35.562790Z","shell.execute_reply.started":"2023-12-17T22:54:35.554575Z","shell.execute_reply":"2023-12-17T22:54:35.561696Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"def initialize_parameters(layer_dims):\n    \"\"\"\n    Initialze using the He initialization method.\n    \n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n        Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n        bl -- bias vector of shape (layer_dims[l], 1)\n    \"\"\"\n    np.random.seed(0)\n    parameters = {}\n    L = len(layer_dims)\n\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * np.sqrt(1. / layer_dims[l - 1])\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        \n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n\n    return parameters","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.564697Z","iopub.execute_input":"2023-12-17T22:54:35.565006Z","iopub.status.idle":"2023-12-17T22:54:35.577370Z","shell.execute_reply.started":"2023-12-17T22:54:35.564978Z","shell.execute_reply":"2023-12-17T22:54:35.576639Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"def linear_forward(A, W, b):\n    \"\"\"\n    Implement the linear part of a layer's forward propagation.\n\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter \n    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n    \"\"\"\n    Z = np.dot(W, A) + b\n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    cache = (A, W, b)\n    \n    return Z, cache","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.578537Z","iopub.execute_input":"2023-12-17T22:54:35.579328Z","iopub.status.idle":"2023-12-17T22:54:35.587990Z","shell.execute_reply.started":"2023-12-17T22:54:35.579298Z","shell.execute_reply":"2023-12-17T22:54:35.587282Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"def linear_activation_forward(A_prev, W, b, activation=''):\n    \"\"\"\n    Implement the forward propagation for the LINEAR->ACTIVATION layer\n\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"softmax\" or \"relu\"\n\n    Returns:\n    A -- the output of the activation function, also called the post-activation value \n    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n                stored for computing the backward pass efficiently\n    \"\"\"\n    Z, linear_cache = linear_forward(A_prev, W, b)\n        \n    match activation:\n        case \"softmax\":\n            A, activation_cache = softmax(Z)\n        case \"relu\":\n            A, activation_cache = relu(Z)\n        case _:\n            assert (False)\n        \n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    cache = (linear_cache, activation_cache)\n\n    return A, cache","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.615384Z","iopub.execute_input":"2023-12-17T22:54:35.615905Z","iopub.status.idle":"2023-12-17T22:54:35.621584Z","shell.execute_reply.started":"2023-12-17T22:54:35.615872Z","shell.execute_reply":"2023-12-17T22:54:35.620762Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"def forward_prop(X, parameters):\n    \"\"\"\n    Implement forward propagation\n\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters()\n\n    Returns:\n    AL -- activation value from the output (last) layer\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() (there are L of them, indexed from 0 to L-1)\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters) // 2  # Dividing by 2 because parameters include W and b for each layer\n    \n    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n    for l in range(1, L):\n        A_prev = A \n        A, cache = linear_activation_forward(A_prev, \n                                             parameters['W' + str(l)], \n                                             parameters['b' + str(l)], \n                                             activation='relu')\n        caches.append(cache)\n    \n    # Implement LINEAR -> SOFTMAX for the last layer.\n    AL, cache = linear_activation_forward(A, \n                                          parameters['W' + str(L)], \n                                          parameters['b' + str(L)], \n                                          activation='softmax')\n    caches.append(cache)\n          \n    return AL, caches\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.623414Z","iopub.execute_input":"2023-12-17T22:54:35.623725Z","iopub.status.idle":"2023-12-17T22:54:35.635442Z","shell.execute_reply.started":"2023-12-17T22:54:35.623696Z","shell.execute_reply":"2023-12-17T22:54:35.634213Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"def compute_cost(AL, Y, type='cross-entropy'):\n    \"\"\"\n    Implement the cost function.\n\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n    Y -- true \"label\" vector, shape (1, number of examples)\n\n    Returns:\n    cost -- cross-entropy cost\n    \"\"\"\n    m = Y.shape[1]\n    \n    match type:\n        case 'mse':\n            # Implement the Mean Squared Error (MSE) cost function\n            cost = (1 / m) * np.sum((AL - Y) ** 2)\n        case 'cross-entropy':\n            # Compute the cross-entropy cost with epsilon to avoid log(0)\n            epsilon = 1e-9\n            cost = -np.sum(Y * np.log(AL + epsilon)) / m\n        case _:\n            assert (False)\n    \n    cost = np.squeeze(cost)  # To make sure the cost's shape is what we expect.\n\n    return cost","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:55:44.972837Z","iopub.execute_input":"2023-12-17T22:55:44.973231Z","iopub.status.idle":"2023-12-17T22:55:44.980049Z","shell.execute_reply.started":"2023-12-17T22:55:44.973201Z","shell.execute_reply":"2023-12-17T22:55:44.979364Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"def relu_backward(dA, cache):\n    \"\"\"\n    Implement the backward propagation for a single RELU unit.\n\n    Arguments:\n    dA -- post-activation gradient, of any shape\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n    \n    # When z <= 0, you should set dz to 0 as well. \n    dZ[Z <= 0] = 0\n    \n    assert (dZ.shape == Z.shape)\n    \n    return dZ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.655386Z","iopub.execute_input":"2023-12-17T22:54:35.656863Z","iopub.status.idle":"2023-12-17T22:54:35.670456Z","shell.execute_reply.started":"2023-12-17T22:54:35.656803Z","shell.execute_reply":"2023-12-17T22:54:35.669445Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"def softmax_backward(AL, Y, cache):\n    \"\"\"\n    Implements the backward propagation for a single softmax unit.\n\n    Arguments:\n    AL -- post-activation output from the softmax layer, of shape (number of classes, number of examples)\n    Y -- true \"label\" vector, same shape as AL\n    cache -- 'Z' where we store for computing backward propagation efficiently\n\n    Returns:\n    dZ -- Gradient of the cost with respect to Z\n    \"\"\"\n    Z = cache\n    dZ = AL - Y\n    \n    assert (dZ.shape == Z.shape)\n    \n    return dZ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.672839Z","iopub.execute_input":"2023-12-17T22:54:35.673463Z","iopub.status.idle":"2023-12-17T22:54:35.682625Z","shell.execute_reply.started":"2023-12-17T22:54:35.673429Z","shell.execute_reply":"2023-12-17T22:54:35.681248Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"def linear_backward(dZ, cache):\n    \"\"\"\n    Implement the linear portion of backward propagation for a single layer (layer l)\n\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n\n    dW = 1./m * np.dot(dZ, A_prev.T)\n    db = 1./m * np.sum(dZ, axis=1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n    \n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    \n    return dA_prev, dW, db","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.684330Z","iopub.execute_input":"2023-12-17T22:54:35.684851Z","iopub.status.idle":"2023-12-17T22:54:35.694746Z","shell.execute_reply.started":"2023-12-17T22:54:35.684818Z","shell.execute_reply":"2023-12-17T22:54:35.693557Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"def linear_activation_backward(dA, Y, cache, activation):\n    \"\"\"\n    Implements the backward propagation for the LINEAR->ACTIVATION layer.\n\n    Arguments:\n    dA -- post-activation gradient for current layer l \n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    activation -- the activation to be used in this layer, stored as a text string: \"softmax\" or \"relu\"\n\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    \n    match activation:\n        case \"softmax\":\n            dZ = softmax_backward(dA, Y, activation_cache)\n            dA_prev, dW, db = linear_backward(dZ, linear_cache)\n        case \"relu\":\n            dZ = relu_backward(dA, activation_cache)\n            dA_prev, dW, db = linear_backward(dZ, linear_cache)\n        case _:\n            assert (False)\n        \n    return dA_prev, dW, db","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.696618Z","iopub.execute_input":"2023-12-17T22:54:35.696990Z","iopub.status.idle":"2023-12-17T22:54:35.712148Z","shell.execute_reply.started":"2023-12-17T22:54:35.696951Z","shell.execute_reply":"2023-12-17T22:54:35.710821Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def back_prop(AL, Y, caches):\n    \"\"\"\n    Implement the backward propagation\n\n    Arguments:\n    AL -- probability vector, output of the forward propagation\n    Y -- true \"label\" vector\n    caches -- list of caches containing:\n                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n                the cache of linear_activation_forward() with \"softmax\" (it's caches[L-1])\n\n    Returns:\n    grads -- A dictionary with the gradients\n        grads[\"dA\" + str(l)] = ... \n        grads[\"dW\" + str(l)] = ...\n        grads[\"db\" + str(l)] = ... \n    \"\"\"\n    grads = {}\n    L = len(caches) # the number of layers\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n    \n    # Initializing the backpropagation\n    epsilon = 1e-9 # to avoid division by zero\n    dAL = -(np.divide(Y, AL + epsilon) - np.divide(1 - Y, 1 - AL + epsilon))\n    \n    # Lth layer gradients.\n    current_cache = caches[-1]\n    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, Y, current_cache, activation='softmax')\n    grads[\"dA\" + str(L - 1)] = dA_prev_temp\n    grads[\"dW\" + str(L)] = dW_temp\n    grads[\"db\" + str(L)] = db_temp\n    \n    for l in reversed(range(L-1)):\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], Y, current_cache, activation='relu')\n        grads[\"dA\" + str(l)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n\n    return grads","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.713682Z","iopub.execute_input":"2023-12-17T22:54:35.714083Z","iopub.status.idle":"2023-12-17T22:54:35.729145Z","shell.execute_reply.started":"2023-12-17T22:54:35.714044Z","shell.execute_reply":"2023-12-17T22:54:35.728101Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"def update_parameters(params, grads, learning_rate):\n    \"\"\"\n    Update parameters using gradient descent.\n\n    Arguments:\n    params -- python dictionary containing the parameters \n    grads -- python dictionary containing the gradients, output of backwards propagation\n\n    Returns:\n    parameters -- python dictionary containing the updated parameters \n        parameters[\"W\" + str(l)] = ... \n        parameters[\"b\" + str(l)] = ...\n    \"\"\"\n    parameters = copy.deepcopy(params)\n    L = len(parameters) // 2\n\n    for l in range(L):\n        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n        \n    return parameters","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.730678Z","iopub.execute_input":"2023-12-17T22:54:35.731354Z","iopub.status.idle":"2023-12-17T22:54:35.746662Z","shell.execute_reply.started":"2023-12-17T22:54:35.731324Z","shell.execute_reply":"2023-12-17T22:54:35.745367Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"def model(X, Y, layers_dims, initial_learning_rate=0.01, decay=10, decay_interval=50, num_iterations=500, print_cost=True):\n    \"\"\"\n    Implements a L-layer neural network\n\n    Arguments:\n    X -- input data, of shape (n_x, number of examples)\n    Y -- true \"label\" vector of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    decay -- The learning rate decay\n    decay_interval -- Specifies on this iteration the decay is applied to the learning rate\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    costs -- cost values over time\n    \"\"\"\n    costs = []\n    learning_rate = initial_learning_rate\n    \n    # Parameters initialization.\n    parameters = initialize_parameters(layers_dims)\n    \n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n\n        # Learning rate decay by factor of decay for every decay_interval iterations\n        if i > 0 and i % decay_interval == 0:\n            learning_rate /= decay\n        \n        AL, caches = forward_prop(X, parameters)\n        cost = compute_cost(AL, Y, type='mse')\n        grads = back_prop(AL, Y, caches)\n        parameters = update_parameters(parameters, grads, learning_rate)\n                \n        # Print the cost every decay_interval iterations\n        if print_cost and i % 25 == 0 or i == num_iterations - 1:\n            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n            print(\"learning_rate after iteration {}: {}\".format(i, learning_rate))\n            \n        if i % 100 == 0 or i == num_iterations:\n            costs.append(cost)\n    \n    return parameters, costs","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.748033Z","iopub.execute_input":"2023-12-17T22:54:35.748401Z","iopub.status.idle":"2023-12-17T22:54:35.763579Z","shell.execute_reply.started":"2023-12-17T22:54:35.748366Z","shell.execute_reply":"2023-12-17T22:54:35.762335Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"# Using the custom deep neural network\n\n## Read data from CSV","metadata":{}},{"cell_type":"code","source":"filepath = '/kaggle/input/digit-recognizer/train.csv'\nraw_data = pd.read_csv(filepath)\nraw_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:35.764857Z","iopub.execute_input":"2023-12-17T22:54:35.765426Z","iopub.status.idle":"2023-12-17T22:54:37.461314Z","shell.execute_reply.started":"2023-12-17T22:54:35.765389Z","shell.execute_reply":"2023-12-17T22:54:37.460624Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare the data","metadata":{}},{"cell_type":"code","source":"X, y = data_prep(raw_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:54:37.462269Z","iopub.execute_input":"2023-12-17T22:54:37.462849Z","iopub.status.idle":"2023-12-17T22:54:37.571320Z","shell.execute_reply.started":"2023-12-17T22:54:37.462824Z","shell.execute_reply":"2023-12-17T22:54:37.570383Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"data.shape = (m = 42000, n = 785)\nX.shape = (784, 42000)\ny_one_hot.shape = (10, 42000)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Define the model","metadata":{}},{"cell_type":"code","source":"# Hyperparameters defining the model\nlayers_dims = [len(X), 10]\nlearning_rate_init = 0.01\nlearning_rate_decay = 10\nlearning_rate_decay_interval = 225\nnum_iterations = 250\n\n# Generate the model\nparameters, costs = model(X=X,\n                          Y=y,\n                          layers_dims=layers_dims,\n                          initial_learning_rate=learning_rate_init,\n                          decay=learning_rate_decay,\n                          decay_interval=learning_rate_decay_interval,\n                          num_iterations=num_iterations,\n                          print_cost=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:57:58.350891Z","iopub.execute_input":"2023-12-17T22:57:58.351232Z","iopub.status.idle":"2023-12-17T22:58:30.388929Z","shell.execute_reply.started":"2023-12-17T22:57:58.351195Z","shell.execute_reply":"2023-12-17T22:58:30.388284Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"Cost after iteration 0: 1.8054447418320307\nlearning_rate after iteration 0: 0.01\nCost after iteration 25: 1.2658746608212943\nlearning_rate after iteration 25: 0.01\nCost after iteration 50: 0.9558928380599668\nlearning_rate after iteration 50: 0.01\nCost after iteration 75: 0.775010709090833\nlearning_rate after iteration 75: 0.01\nCost after iteration 100: 0.6669521556078212\nlearning_rate after iteration 100: 0.01\nCost after iteration 125: 0.599403322476835\nlearning_rate after iteration 125: 0.01\nCost after iteration 150: 0.5535807366258934\nlearning_rate after iteration 150: 0.01\nCost after iteration 175: 0.5209816623938733\nlearning_rate after iteration 175: 0.01\nCost after iteration 200: 0.4974661788079457\nlearning_rate after iteration 200: 0.01\nCost after iteration 225: 0.48059481443897467\nlearning_rate after iteration 225: 0.001\nCost after iteration 249: 0.47927914053149817\nlearning_rate after iteration 249: 0.001\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Predict on training set","metadata":{}},{"cell_type":"code","source":"def predict_train_data(X, y, parameters):\n    \"\"\"\n    This function is used to predict the results of a L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    y -- true \"label\" vector (one-hot encoded)\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    n = len(parameters) // 2\n\n    # Forward propagation\n    AL, caches = forward_prop(X, parameters)\n\n    # Convert predictions and true labels to categorical form\n    predictions = np.argmax(AL, axis=0)\n    true_labels = np.argmax(y, axis=0)\n\n    # Calculate accuracy\n    accuracy = np.sum(predictions == true_labels) / m\n\n    # Print results\n    print(\"Accuracy: \" + str(accuracy * 100) + '%')\n\n    return predictions\n\n# Make the predicitons on training data set\npred_train = predict_train_data(X, y, parameters)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:58:44.720612Z","iopub.execute_input":"2023-12-17T22:58:44.720936Z","iopub.status.idle":"2023-12-17T22:58:44.775869Z","shell.execute_reply.started":"2023-12-17T22:58:44.720912Z","shell.execute_reply":"2023-12-17T22:58:44.775219Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"Accuracy: 83.71190476190476%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Predict using test set and plot some random predictions","metadata":{}},{"cell_type":"code","source":"def prepare_test_data(raw):\n    \"\"\"\n    Prepares test data (without labels)\n\n    Arguments:\n    raw -- raw test data read from a csv file\n\n    Returns:\n    X -- normalized test data\n    \"\"\"\n    X = np.array(raw) / 255\n    X = X.T  # Transpose to match the expected shape (number_of_features, number_of_examples)\n    \n    print(\"X_test.shape =\", X.shape)\n    \n    return X\n\ndef predict_test_data(X, parameters):\n    \"\"\"\n    This function is used to predict the results of a L-layer neural network.\n\n    Arguments:\n    X -- data set of examples you would like to label\n    parameters -- parameters of the trained model\n\n    Returns:\n    p -- predictions for the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    n = len(parameters) // 2\n\n    # Forward propagation\n    AL, caches = forward_prop(X, parameters)\n\n    # Convert predictions to categorical form\n    predictions = np.argmax(AL, axis=0)\n\n    return predictions\n\n# Read and prepare test data\nfilepath = '/kaggle/input/digit-recognizer/test.csv'\nraw_test_data = pd.read_csv(filepath)\nX_test = prepare_test_data(raw_test_data)\n\n# Make the predicitons on test data set\npred_test = predict_test_data(X_test, parameters)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:58:49.315075Z","iopub.execute_input":"2023-12-17T22:58:49.315408Z","iopub.status.idle":"2023-12-17T22:58:50.502632Z","shell.execute_reply.started":"2023-12-17T22:58:49.315383Z","shell.execute_reply":"2023-12-17T22:58:50.501833Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"X_test.shape = (784, 28000)\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_images_with_predictions(X, predictions, num_images=10):\n    \"\"\"\n    Plots a random selection of images with their predicted labels.\n\n    Arguments:\n    X -- dataset of shape (number_of_features, number_of_examples)\n    predictions -- array of predicted labels for the dataset\n    num_images -- number of random images to display\n    \"\"\"\n    fig, axes = plt.subplots(1, num_images, figsize=(20, 4))\n    \n    for i, ax in enumerate(axes):\n        # Randomly select an image\n        idx = np.random.randint(X.shape[1])\n        img = X[:, idx].reshape(28, 28)  # Reshape the image to 28x28\n\n        ax.imshow(img, cmap='gray')\n        ax.set_title(f'Predicted: {predictions[idx]}')\n        ax.axis('off')\n\n    plt.show()\n\n# Plot images with predictions\nplot_images_with_predictions(X_test, pred_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:59:44.338846Z","iopub.execute_input":"2023-12-17T22:59:44.339235Z","iopub.status.idle":"2023-12-17T22:59:44.890085Z","shell.execute_reply.started":"2023-12-17T22:59:44.339204Z","shell.execute_reply":"2023-12-17T22:59:44.889078Z"},"trusted":true},"execution_count":164,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 2000x400 with 10 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create file of predictions for submission","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame with ImageId and Label\nresult_df = pd.DataFrame({\n    'ImageId': range(1, len(pred_test) + 1),\n    'Label': pred_test\n})\n\n# Save to CSV\nfilename = \"submission.csv\"\nresult_df.to_csv(filename, index=False)\n\nprint(f'Saved predictions to {filename}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T22:59:03.706647Z","iopub.execute_input":"2023-12-17T22:59:03.707027Z","iopub.status.idle":"2023-12-17T22:59:03.743362Z","shell.execute_reply.started":"2023-12-17T22:59:03.706996Z","shell.execute_reply":"2023-12-17T22:59:03.741981Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"Saved predictions to submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}